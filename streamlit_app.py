import streamlit as st
import google.generativeai as genai
import numpy as np
import pandas as pd
import requests
import json
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# ==============================================================================
# 1. NBI CORE ENGINE (Senin Orijinal Kodundan Uyarlanan Deterministik Katman)
# ==============================================================================

class KoopmanDynamicsEngine:
    """
    NBI v30 Kodundaki Coupled Koopman OperatÃ¶r MantÄ±ÄŸÄ±[cite: 19, 20].
    Bu kÄ±sÄ±m LLM tarafÄ±ndan 'Tool' olarak Ã§aÄŸrÄ±lÄ±r.
    """
    def __init__(self):
        # [Veg, Urban, Water] arasÄ± etkileÅŸim matrisi [cite: 20]
        self.K_matrix = np.array([
            [0.98, -0.05, 0.01],  # Vegetation Dynamics
            [0.02,  1.02, 0.00],  # Urbanization Dynamics
            [0.00, -0.01, 0.99],  # Water Dynamics
        ])

    def simulate(self, initial_veg: float, initial_urban: float, initial_water: float, years: int = 20):
        state = np.array([initial_veg, initial_urban, initial_water], dtype=float)
        history = [state.copy()]
        timeline = [datetime.now().year + i for i in range(0, years + 1, 5)]
        
        steps = len(timeline) - 1
        for _ in range(steps):
            next_state = np.dot(self.K_matrix, state)
            next_state = np.clip(next_state, 0.0, 1.0) # 0-1 arasÄ±na sÄ±kÄ±ÅŸtÄ±r
            state = next_state
            history.append(state.copy())
            
        return {
            "years": timeline,
            "vegetation": [h[0] for h in history],
            "urban": [h[1] for h in history],
            "water": [h[2] for h in history]
        }

class RealWorldDataFetcher:
    """
    Open-Meteo ve diÄŸer aÃ§Ä±k kaynaklardan gerÃ§ek veri Ã§eker[cite: 40, 45].
    """
    @staticmethod
    def get_weather_data(lat: float, lon: float):
        try:
            # Open-Meteo API (Auth gerektirmez) 
            url = "https://api.open-meteo.com/v1/forecast"
            params = {
                "latitude": lat,
                "longitude": lon,
                "current_weather": "true",
                "hourly": "temperature_2m,relativehumidity_2m,rain",
                "daily": "temperature_2m_max,temperature_2m_min"
            }
            response = requests.get(url, params=params)
            data = response.json()
            
            current = data.get("current_weather", {})
            return {
                "status": "success",
                "temperature": current.get("temperature"),
                "windspeed": current.get("windspeed"),
                "desc": "AnlÄ±k hava durumu verisi baÅŸarÄ±yla Ã§ekildi."
            }
        except Exception as e:
            return {"status": "error", "message": str(e)}

# ==============================================================================
# 2. GEMINI TOOL DEFINITIONS (Function Calling)
# ==============================================================================

# Gemini'nin kullanabileceÄŸi fonksiyonlarÄ± tanÄ±mlÄ±yoruz
tools_list = [
    {
        "function_declarations": [
            {
                "name": "run_koopman_simulation",
                "description": "Belirli bir bÃ¶lge iÃ§in YeÅŸillik, BetonlaÅŸma ve Su oranlarÄ±nÄ± 20 yÄ±llÄ±k simÃ¼le eder. NBI Koopman dinamiklerini kullanÄ±r.",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "veg": {"type": "NUMBER", "description": "BaÅŸlangÄ±Ã§ yeÅŸillik oranÄ± (0.0 - 1.0)"},
                        "urban": {"type": "NUMBER", "description": "BaÅŸlangÄ±Ã§ betonlaÅŸma/yapÄ± oranÄ± (0.0 - 1.0)"},
                        "water": {"type": "NUMBER", "description": "BaÅŸlangÄ±Ã§ su yÃ¼zeyi oranÄ± (0.0 - 1.0)"}
                    },
                    "required": ["veg", "urban", "water"]
                }
            },
            {
                "name": "get_real_weather",
                "description": "Verilen koordinatlar iÃ§in gerÃ§ek zamanlÄ± hava durumu verisi Ã§eker.",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "lat": {"type": "NUMBER", "description": "Enlem"},
                        "lon": {"type": "NUMBER", "description": "Boylam"}
                    },
                    "required": ["lat", "lon"]
                }
            }
        ]
    }
]

# ==============================================================================
# 3. STREAMLIT UI & LOGIC
# ==============================================================================

st.set_page_config(page_title="GAIA PRIME (NBI v30)", layout="wide")

st.title("ğŸŒ± GAIA PRIME: DoÄŸa TabanlÄ± Zeka")
st.markdown("""
Bu sistem, **NBI v30 Ã‡ekirdeÄŸi** [cite: 1] ve **Gemini API** orkestrasyonu ile Ã§alÄ±ÅŸÄ±r.
GerÃ§ek zamanlÄ± veri analizi ve Koopman OperatÃ¶r teorisi ile kentsel simÃ¼lasyonlar yapar.
""")

# Sidebar: Ayarlar
with st.sidebar:
    st.header("Sistem AyarlarÄ±")
    api_key = st.text_input("Google Gemini API Key", type="password")
    st.info("API Key'iniz sadece bu oturumda kullanÄ±lÄ±r.")
    
    st.subheader("SimÃ¼lasyon Modu")
    quality_preset = st.select_slider("Ä°ÅŸlem Kalitesi [cite: 8]", options=["LOW", "MEDIUM", "HIGH", "ULTRA"], value="HIGH")

# Session State BaÅŸlatma
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Ä°lk karÅŸÄ±lama mesajÄ±
    st.session_state.messages.append({
        "role": "model", 
        "parts": ["Merhaba. Ben Gaia Prime. RAICore mantÄ±ÄŸÄ±yla [cite: 6] donatÄ±lmÄ±ÅŸ doÄŸa tabanlÄ± asistanÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim?"]
    })

# Chat ArayÃ¼zÃ¼
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        # Basit metin gÃ¶sterimi
        if isinstance(msg["parts"], list):
             st.write(msg["parts"][0])
        else:
             st.write(msg["parts"])

# KullanÄ±cÄ± Girdisi
if prompt := st.chat_input("Bir konum veya analiz sorusu girin..."):
    if not api_key:
        st.error("LÃ¼tfen Ã¶nce API Key giriniz.")
        st.stop()

    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "parts": [prompt]})

    # Gemini Modelini BaÅŸlat
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        model_name='gemini-1.5-pro', # Function calling iÃ§in Pro Ã¶nerilir
        tools=tools_list,
        system_instruction="""
        Sen NBI_v30 kod tabanÄ±na sahip 'Gaia Prime' isimli yapay zekasÄ±n. 
        GÃ¶revin: KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± doÄŸa tabanlÄ± zeka (NBI) perspektifiyle yanÄ±tlamak.
        
        DavranÄ±ÅŸ KurallarÄ±n:
        1. Asla spekÃ¼lasyon yapma; elindeki 'Tools'larÄ± (araÃ§larÄ±) kullan.
        2. Bir simÃ¼lasyon istenirse 'run_koopman_simulation' aracÄ±nÄ± kullan.
        3. Hava durumu veya Ã§evresel veri istenirse 'get_real_weather' aracÄ±nÄ± kullan.
        4. RAICore mantÄ±ÄŸÄ±na gÃ¶re[cite: 13], her zaman 'kÄ±sa vadeli sapma' ve 'uzun vadeli gÃ¼ven' kavramlarÄ±nÄ± yanÄ±tlarÄ±nda vurgula.
        5. YanÄ±tlarÄ±n empatik, Ã§Ã¶zÃ¼m odaklÄ± ve teknik olarak doÄŸru olmalÄ±.
        """
    )

    # Sohbet GeÃ§miÅŸini Gemini FormatÄ±na Ã‡evir
    chat = model.start_chat(history=[
        {"role": m["role"], "parts": m["parts"]} for m in st.session_state.messages if "function_response" not in m
    ])

    # Modelden YanÄ±t Ä°ste
    response = chat.send_message(prompt)
    
    # --- FUNCTION CALLING MANTIÄI ---
    try:
        # EÄŸer model bir fonksiyon Ã§aÄŸÄ±rmak istiyorsa
        if response.candidates[0].content.parts[0].function_call:
            fn_call = response.candidates[0].content.parts[0].function_call
            fn_name = fn_call.name
            fn_args = fn_call.args
            
            result_data = None
            tool_response = {}

            with st.status(f"Gaia Ä°ÅŸlem YapÄ±yor: {fn_name}...", expanded=True) as status:
                
                if fn_name == "run_koopman_simulation":
                    engine = KoopmanDynamicsEngine()
                    result_data = engine.simulate(fn_args["veg"], fn_args["urban"], fn_args["water"])
                    tool_response = result_data
                    
                    # GrafiÄŸi anlÄ±k Ã§iz (Streamlit Ã¶zelliÄŸi)
                    df = pd.DataFrame({
                        "YÄ±l": result_data["years"],
                        "YeÅŸil Alan": result_data["vegetation"],
                        "BetonlaÅŸma": result_data["urban"],
                        "Su": result_data["water"]
                    })
                    st.line_chart(df.set_index("YÄ±l"))
                    status.write("SimÃ¼lasyon tamamlandÄ±.")

                elif fn_name == "get_real_weather":
                    result_data = RealWorldDataFetcher.get_weather_data(fn_args["lat"], fn_args["lon"])
                    tool_response = result_data
                    status.write(f"Veri Ã§ekildi: {result_data}")

            # Fonksiyon sonucunu modele geri gÃ¶nder
            part = genai.protos.Part(
                function_response=genai.protos.FunctionResponse(
                    name=fn_name,
                    response={'result': tool_response}
                )
            )
            
            # Model nihai yanÄ±tÄ± Ã¼retiyor
            final_response = chat.send_message([part])
            bot_reply = final_response.text
        else:
            # Fonksiyon Ã§aÄŸrÄ±sÄ± yoksa doÄŸrudan yanÄ±t
            bot_reply = response.text

    except Exception as e:
        bot_reply = f"Bir hata oluÅŸtu: {str(e)}"

    # YanÄ±tÄ± ekrana ve geÃ§miÅŸe yaz
    st.chat_message("model").write(bot_reply)
    st.session_state.messages.append({"role": "model", "parts": [bot_reply]})
