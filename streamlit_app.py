import streamlit as st
import google.generativeai as genai
import numpy as np
import pandas as pd
import requests
import json
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from google.api_core.exceptions import NotFound, InvalidArgument

# ==============================================================================
# 1. NBI ENGINE (ABICore Logic)
# ==============================================================================

class KoopmanDynamicsEngine:
    """
    ABICore (Alper-Based Intelligence) MantÄ±ÄŸÄ±.
    YeÅŸil alan, beton ve su arasÄ±ndaki etkileÅŸimi matris tabanlÄ± simÃ¼le eder.
    """
    def __init__(self):
        # [Veg, Urban, Water] arasÄ± etkileÅŸim matrisi
        self.K_matrix = np.array([
            [0.98, -0.05, 0.01],  # Vegetation Dynamics
            [0.02,  1.02, 0.00],  # Urbanization Dynamics
            [0.00, -0.01, 0.99],  # Water Dynamics
        ])

    def simulate(self, initial_veg: float, initial_urban: float, initial_water: float, years: int = 20):
        state = np.array([initial_veg, initial_urban, initial_water], dtype=float)
        history = [state.copy()]
        timeline = [datetime.now().year + i for i in range(0, years + 1, 5)]
        
        steps = len(timeline) - 1
        for _ in range(steps):
            next_state = np.dot(self.K_matrix, state)
            next_state = np.clip(next_state, 0.0, 1.0) # 0-1 arasÄ±na sÄ±kÄ±ÅŸtÄ±r
            state = next_state
            history.append(state.copy())
            
        return {
            "years": timeline,
            "vegetation": [h[0] for h in history],
            "urban": [h[1] for h in history],
            "water": [h[2] for h in history]
        }

class RealWorldDataFetcher:
    """
    Open-Meteo ve diÄŸer aÃ§Ä±k kaynaklardan gerÃ§ek veri Ã§eker.
    """
    @staticmethod
    def get_weather_data(lat: float, lon: float):
        try:
            # Open-Meteo API (Auth gerektirmez)
            url = "https://api.open-meteo.com/v1/forecast"
            params = {
                "latitude": lat,
                "longitude": lon,
                "current_weather": "true",
                "hourly": "temperature_2m,relativehumidity_2m,rain",
                "daily": "temperature_2m_max,temperature_2m_min"
            }
            response = requests.get(url, params=params)
            data = response.json()
            
            current = data.get("current_weather", {})
            return {
                "status": "success",
                "temperature": current.get("temperature"),
                "windspeed": current.get("windspeed"),
                "desc": "AnlÄ±k hava durumu verisi baÅŸarÄ±yla Ã§ekildi."
            }
        except Exception as e:
            return {"status": "error", "message": str(e)}

# ==============================================================================
# 2. GEMINI TOOL DEFINITIONS
# ==============================================================================

tools_list = [
    {
        "function_declarations": [
            {
                "name": "run_koopman_simulation",
                "description": "Belirli bir bÃ¶lge iÃ§in YeÅŸillik, BetonlaÅŸma ve Su oranlarÄ±nÄ± ABICore dinamikleriyle 20 yÄ±llÄ±k simÃ¼le eder.",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "veg": {"type": "NUMBER", "description": "BaÅŸlangÄ±Ã§ yeÅŸillik oranÄ± (0.0 - 1.0)"},
                        "urban": {"type": "NUMBER", "description": "BaÅŸlangÄ±Ã§ betonlaÅŸma/yapÄ± oranÄ± (0.0 - 1.0)"},
                        "water": {"type": "NUMBER", "description": "BaÅŸlangÄ±Ã§ su yÃ¼zeyi oranÄ± (0.0 - 1.0)"}
                    },
                    "required": ["veg", "urban", "water"]
                }
            },
            {
                "name": "get_real_weather",
                "description": "Verilen koordinatlar iÃ§in gerÃ§ek zamanlÄ± hava durumu verisi Ã§eker.",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "lat": {"type": "NUMBER", "description": "Enlem"},
                        "lon": {"type": "NUMBER", "description": "Boylam"}
                    },
                    "required": ["lat", "lon"]
                }
            }
        ]
    }
]

# ==============================================================================
# 3. STREAMLIT UI & LOGIC
# ==============================================================================

st.set_page_config(page_title="GAIA PRIME (NBI v30)", layout="wide")

st.title("ğŸŒ± GAIA PRIME")
st.markdown("### Powered by ABICoreâ„¢ Architecture")
st.caption("DoÄŸa TabanlÄ± Zeka (NBI) ve GerÃ§ek ZamanlÄ± Veri Orkestrasyonu")

# Sidebar: Ayarlar
with st.sidebar:
    st.header("Sistem AyarlarÄ±")
    api_key = st.text_input("Google Gemini API Key", type="password")
    st.info("API Key'iniz sadece bu oturumda kullanÄ±lÄ±r.")
    
    st.subheader("SimÃ¼lasyon Modu")
    quality_preset = st.select_slider("ABICore Ä°ÅŸlem Kalitesi", options=["ECO", "BALANCED", "HIGH", "ULTRA"], value="HIGH")
    
    st.divider()
    st.markdown("**ABICore Durumu:** ğŸŸ¢ Aktif")

# Session State BaÅŸlatma
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Ä°lk karÅŸÄ±lama mesajÄ± (ABICore ismiyle)
    st.session_state.messages.append({
        "role": "model", 
        "parts": ["Merhaba. Ben Gaia Prime. [cite_start]**ABICore** mantÄ±ÄŸÄ±yla [cite: 6] donatÄ±lmÄ±ÅŸ doÄŸa tabanlÄ± asistanÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim?"]
    })

# Chat ArayÃ¼zÃ¼
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if isinstance(msg["parts"], list):
             st.write(msg["parts"][0])
        else:
             st.write(msg["parts"])

# KullanÄ±cÄ± Girdisi
if prompt := st.chat_input("Bir konum veya analiz sorusu girin..."):
    if not api_key:
        st.error("LÃ¼tfen sol menÃ¼den API Key giriniz.")
        st.stop()

    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "parts": [prompt]})

    # Gemini Modelini BaÅŸlat (HATA DÃœZELTÄ°LDÄ°: gemini-1.5-flash)
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        model_name='gemini-1.5-flash', 
        tools=tools_list,
        system_instruction="""
        Sen 'Gaia Prime' isimli yapay zekasÄ±n. Arka planda **ABICore** (Alper-Based Intelligence Core) mimarisini kullanÄ±yorsun.
        
        GÃ¶revin: KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± doÄŸa tabanlÄ± zeka (NBI) perspektifiyle yanÄ±tlamak.
        
        DavranÄ±ÅŸ KurallarÄ±n:
        1. Kendini tanÄ±tÄ±rken veya mantÄ±ÄŸÄ±nÄ± aÃ§Ä±klarken her zaman 'ABICore' ismini kullan.
        2. Asla spekÃ¼lasyon yapma; elindeki 'Tools'larÄ± (araÃ§larÄ±) kullan.
        3. Bir simÃ¼lasyon istenirse 'run_koopman_simulation' aracÄ±nÄ± kullan.
        4. Hava durumu veya Ã§evresel veri istenirse 'get_real_weather' aracÄ±nÄ± kullan.
        5. ABICore mantÄ±ÄŸÄ±na gÃ¶re, her zaman 'kÄ±sa vadeli sapma' ve 'uzun vadeli gÃ¼ven' kavramlarÄ±nÄ± yanÄ±tlarÄ±nda vurgula.
        6. YanÄ±tlarÄ±n empatik, Ã§Ã¶zÃ¼m odaklÄ± ve teknik olarak doÄŸru olmalÄ±.
        """
    )

    # Sohbet GeÃ§miÅŸini Gemini FormatÄ±na Ã‡evir
    chat = model.start_chat(history=[
        {"role": m["role"], "parts": m["parts"]} for m in st.session_state.messages if "function_response" not in m
    ])

    # Modelden YanÄ±t Ä°ste
    try:
        response = chat.send_message(prompt)
        
        # --- FUNCTION CALLING MANTIÄI ---
        if response.candidates and response.candidates[0].content.parts:
            part = response.candidates[0].content.parts[0]
            
            if part.function_call:
                fn_call = part.function_call
                fn_name = fn_call.name
                fn_args = fn_call.args
                
                result_data = None
                tool_response = {}

                with st.status(f"ABICore Ä°ÅŸlem YapÄ±yor: {fn_name}...", expanded=True) as status:
                    
                    if fn_name == "run_koopman_simulation":
                        engine = KoopmanDynamicsEngine()
                        # ArgÃ¼manlarÄ± gÃ¼venli Ã§ekelim
                        veg = fn_args.get("veg", 0.3)
                        urban = fn_args.get("urban", 0.5)
                        water = fn_args.get("water", 0.2)
                        
                        result_data = engine.simulate(veg, urban, water)
                        tool_response = result_data
                        
                        # GrafiÄŸi anlÄ±k Ã§iz
                        df = pd.DataFrame({
                            "YÄ±l": result_data["years"],
                            "YeÅŸil Alan": result_data["vegetation"],
                            "BetonlaÅŸma": result_data["urban"],
                            "Su": result_data["water"]
                        })
                        st.line_chart(df.set_index("YÄ±l"))
                        status.write("ABICore SimÃ¼lasyonu tamamlandÄ±.")

                    elif fn_name == "get_real_weather":
                        lat = fn_args.get("lat")
                        lon = fn_args.get("lon")
                        if lat and lon:
                            result_data = RealWorldDataFetcher.get_weather_data(lat, lon)
                            tool_response = result_data
                            status.write(f"Veri Ã§ekildi: {result_data}")
                        else:
                            tool_response = {"error": "Koordinat eksik"}

                # Fonksiyon sonucunu modele geri gÃ¶nder
                function_response_part = genai.protos.Part(
                    function_response=genai.protos.FunctionResponse(
                        name=fn_name,
                        response={'result': tool_response}
                    )
                )
                
                # Model nihai yanÄ±tÄ± Ã¼retiyor
                final_response = chat.send_message([function_response_part])
                bot_reply = final_response.text
            else:
                bot_reply = response.text
        else:
            bot_reply = "ABICore ÅŸu an yanÄ±t Ã¼retemedi. LÃ¼tfen tekrar deneyin."

    except NotFound:
        bot_reply = "Model bulunamadÄ± hatasÄ±. LÃ¼tfen kodun 'gemini-1.5-flash' kullandÄ±ÄŸÄ±ndan emin olun."
    except Exception as e:
        bot_reply = f"Bir hata oluÅŸtu: {str(e)}"

    # YanÄ±tÄ± ekrana ve geÃ§miÅŸe yaz
    st.chat_message("model").write(bot_reply)
    st.session_state.messages.append({"role": "model", "parts": [bot_reply]})
